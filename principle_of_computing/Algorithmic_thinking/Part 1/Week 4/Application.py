#!/Applications/anaconda/bin/python


from collections import deque

import urllib
import random
import time
import math

# CodeSkulptor import
#import simpleplot
#import codeskulptor
#codeskulptor.set_timeout(60)

# Desktop imports
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
import numpy as np
import timeit

##########################################################################
###
class UPATrial:
    """
    Simple class to encapsulate optimizated trials for the UPA algorithm
    
    Maintains a list of node numbers with multiple instance of each number.
    The number of instances of each node number are
    in the same proportion as the desired probabilities
    
    Uses random.choice() to select a node number from this list for each trial.
    """

    def __init__(self, num_nodes):
        """
        Initialize a UPATrial object corresponding to a 
        complete graph with num_nodes nodes
        
        Note the initial list of node numbers has num_nodes copies of
        each node number
        """
        self._num_nodes = num_nodes
        self._node_numbers = [node for node in range(num_nodes) for dummy_idx in range(num_nodes)]


    def run_trial(self, num_nodes):
        """
        Conduct num_nodes trials using by applying random.choice()
        to the list of node numbers
        
        Updates the list of node numbers so that each node number
        appears in correct ratio
        
        Returns:
        Set of nodes
        """
        
        # compute the neighbors for the newly-created node
        new_node_neighbors = set()
        for _ in range(num_nodes):
            new_node_neighbors.add(random.choice(self._node_numbers))
        
        # update the list of node numbers so that each node number 
        # appears in the correct ratio
        self._node_numbers.append(self._num_nodes)
        for dummy_idx in range(len(new_node_neighbors)):
            self._node_numbers.append(self._num_nodes)
        self._node_numbers.extend(list(new_node_neighbors))
        
        #update the number of nodes
        self._num_nodes += 1
        return new_node_neighbors

#######################################################
def dpa(final_size, seed_size):
    """
    This algorithm starts with a complete (fully connected) graph) and
    incrementally adds nodes and their adjacency lists. The seed size is the
    number of nodes for the complete graph. The final size is the total number
    of nodes in the final graph.

    final size - seed size = number of nodes to be added with the DPA trials
    algorithm. When the DPA trial object is created, pass in the total number
    nodes desired in the final graph. Each time the trial function is called,
    passed in the node ID and the trial function returns the adjacency list
    for that node.
    """
    if not seed_size <= final_size:
        print('Error. Seed size must be smaller than or equal to final size.')
        exit(-1)

    graph = make_complete_ugraph(seed_size)
    #graph = make_complete_graph(seed_size)
    dpa_helper = UPATrial(seed_size)
    # The node IDs for the seed graph range from 0 - seed_size -1.
    # Therefore the the number seed_size is really the ID for the first
    # node to be generated by DPA trial
    for node in range(seed_size, final_size):
        adj_list = dpa_helper.run_trial(seed_size)
        graph[node] = adj_list

    #adj_list = dpa_helper.run_trial(seed_size)
    #graph[node] = adj_list
    #These lines are correct, but you need to add edges from all of "adj_list" to "node".

    return graph


################################################################
# Provided code

def copy_graph(graph):
    """
    Make a copy of a graph
    """
    new_graph = {}
    for node in graph:
        new_graph[node] = set(graph[node])
    return new_graph

#################################################################
#
def delete_node(ugraph, node):
    """
    Delete a node from an undirected graph
    """
    try:
        neighbors = ugraph[node]
        ugraph.pop(node)
        for neighbor in neighbors:
            ugraph[neighbor].remove(node)
    except KeyError as e:
        print('I got a KeyError - reason "%s"' % str(e))
###################################################
##
def targeted_order(ugraph):
    """
    Compute a targeted attack order consisting
    of nodes of maximal degree
    
    Returns:
    A list of nodes
    """
    # copy the graph
    new_graph = copy_graph(ugraph)
    
    order = []    
    while len(new_graph) > 0:
        max_degree = -1
        for node in new_graph:
            if len(new_graph[node]) > max_degree:
                max_degree = len(new_graph[node])
                max_degree_node = node
        
        neighbors = new_graph[max_degree_node]
        new_graph.pop(max_degree_node)
        for neighbor in neighbors:
            new_graph[neighbor].remove(max_degree_node)

        order.append(max_degree_node)
        
    return order

#######################################################
def tem_fast_targeted_order(ugraph):
    '''
    genrate a attack order which always attack the currently 
        'richest' node in the graph for each step
    '''
    new_graph = copy_graph(ugraph)
    degree_sets = [set() for i in range(len(new_graph))]
    for k in range(len(new_graph)):
        degree_sets[len(new_graph[k])].add(k)
    L = []
    for k in range(len(new_graph)):
        iter = len(new_graph) - k - 1
        while degree_sets[iter] != set():
            u = degree_sets[iter].pop()
            for neighbor in new_graph[u]:
                d = len(new_graph[neighbor])
                degree_sets[d].remove(neighbor)
                degree_sets[d-1].add(neighbor)
            L.append(u)
            delete_node(new_graph, u)
    return L
########################################################
##
def fast_targeted_order(ugraph):
    """
    """
    # This is the list of sets
    num_of_nodes = len(ugraph)

    local_graph = dict(ugraph)
 
    # lines 1 and 2
    degree_sets = [set([])]*num_of_nodes

    # lines 3, 4, 5
    for i in range(0, num_of_nodes):
        adj_set = local_graph.get(i)
        if adj_set is None:
            degree = 0
        else:
            degree = len(adj_set)
        degree_sets[degree] = degree_sets[degree].union(set([i]))
        
    # line 6
    L = []

    # line 7
    i = 0

    # line 8
    for k in reversed(range(num_of_nodes)):
        # line 9
        while len(degree_sets[k]) != 0:            
            #  line 10 and 11
            u = degree_sets[k].pop()
 
            # line 12
            u_neighbors = local_graph.get(u)

            if u_neighbors is not None:
                for v in u_neighbors:
                    # line 13
                    v_adj_set = local_graph.get(v)
                    d = len(v_adj_set)
                    
                    # line 14
                    #d_set = degree_sets[d]
                    degree_sets[d].difference_update( set([v]) )
                
                    # line 15
                    degree_sets[d-1] = degree_sets[d-1].union(set([v]))

            # line 16
            L.append(u)
            
            # line 17
            i += 1

            #line 18
            delete_node(local_graph, u)

    return L
                

###################################################################
###
def generate_ugraph(num_of_nodes, probability):

    if (num_of_nodes <= 0):
        return {}
    else:
        graph = {}

        # initialize the adjacency set for every node to an empty set
        for node in range(0, num_of_nodes):
            graph.update({node: set([])})

        for node in range(0, num_of_nodes):
            for destination in range(0, num_of_nodes):
                if node != destination:
                    random_a = random.random()
                    if (random_a < probability):
                        curr_node_adj_set = graph.get(node)
                        curr_node_adj_set = curr_node_adj_set.union(set([destination]))
                        graph.update({node: curr_node_adj_set})
                        dest_node_adj_set  = graph.get(destination)
                        dest_node_adj_set  = dest_node_adj_set.union( set([node]) )
                        graph.update({destination: dest_node_adj_set})

        return graph

####################################################################
##
def make_complete_graph(num_of_nodes):

    """ Takes the number of nodes num_of_nodes and returns a dictionary
    corresponding to a complete directed graph with the specified number
    of nodes. A complete graph contains all possible edges subject to
    the restriction that self-loops are not allowed.
    """

    if num_of_nodes <= 0:
        return {}
    else:
        graph = {}
        for source in range(0, num_of_nodes):
            nodes = []
            for destination in range(0, num_of_nodes):
                if source != destination:
                    nodes.append(destination)
            graph.update({source: nodes})
        return graph

####################################################################
####
def make_complete_ugraph(num_of_nodes):    
    """ 
    Takes the number of nodes num_of_nodes and returns a dictionary
    corresponding to a complete directed graph with the specified number
    of nodes. A complete graph contains all possible edges subject to
    the restriction that self-loops are not allowed.
    """

    if num_of_nodes <= 0:
        return {}
    else:
        graph = {}
        for node in range(0, num_of_nodes):
            graph.update( {node: set([])} )
            
        for node1 in range(0, num_of_nodes):
            for node2 in range(0, num_of_nodes):
                if node1 != node2:
                    node1_adj_set = graph.get(node1)
                    node1_adj_set = node1_adj_set.union(set([node2]))
                    graph.update({node1: node1_adj_set})
                    node2_adj_set = graph.get(node2)
                    node2_adj_set = node2_adj_set.union(set([node1]))
                    graph.update({node2: node2_adj_set})
                
        return graph


##########################################################
# Code for loading computer network graph
def load_graph(graph_url):
    """
    Function that loads a graph given the URL
    for a text representation of the graph
    
    Returns a dictionary that models a graph
    """
    #graph_file = urllib2.urlopen(graph_url)
    graph_file = urllib.request.urlopen(graph_url)
    #graph_text = graph_file.read()
    graph_text = graph_file.read().decode("utf-8")
    graph_lines = graph_text.split('\n')
    graph_lines = graph_lines[ : -1]
    
    print ("Loaded graph with", len(graph_lines), "nodes")
    
    answer_graph = {}
    for line in graph_lines:
        neighbors = line.split(' ')
        node = int(neighbors[0])
        answer_graph[node] = set([])
        for neighbor in neighbors[1 : -1]:
            answer_graph[node].add(int(neighbor))

    return answer_graph

#############################################################
def bfs_visited(ugraph, start_node):

    node_queue = deque()
    visited = set([start_node])
    node_queue.append(start_node)

    while len(node_queue) > 0:
        current_node = node_queue.popleft()
        neighbors = ugraph.get(current_node)
        if neighbors != None:
            for node in neighbors:
                if node not in visited:
                    visited = visited.union( set([node]))
                    node_queue.append(node)

    return visited

############################################################
#
def cc_visited(ugraph):   
 
    remaining_nodes = set(ugraph.keys())
    connected_components = []

    while ( len(remaining_nodes) != 0):
        next_node = remaining_nodes.pop()
        visited_nodes = bfs_visited(ugraph, next_node)
        connected_components.append(visited_nodes)
        remaining_nodes.difference_update(visited_nodes)
 
    return connected_components    

############################################################
##
def largest_cc_size(ugraph):

    connected_components = cc_visited(ugraph)

    size = 0

    for con_comp in connected_components:
        new_size = len(con_comp)
        if new_size > size:
            size = new_size

    return size   


###############################################################
##
def compute_resilience(ugraph, attack_order):

    # create copy of the input graph
    graph_copy = dict(ugraph)
    result_list = []
    result_list.append(largest_cc_size(graph_copy))
    
    for node in attack_order:
        curr_adj_list = graph_copy.get(node)
        #remove the node from the dict

        try:
            del graph_copy[node]
        except KeyError as e:
            print('I got a KeyError - reason "%s"' % str(e))
             
        # remove the current node from the rest
        if curr_adj_list is not None:
            for adj_node in curr_adj_list:
                adj_set = graph_copy.get(adj_node)
                if adj_set != None:
                    if node in adj_set:
                        adj_set.remove(node)

        result_list.append( largest_cc_size(graph_copy) )

    return result_list


#########################################################################
##
def plot_graphs_hw_one(network_graph_res, er_graph_res, upa_graph_res ):
    """
    """
    #print( len(network_graph_res) )
    #print( len(er_graph_res) )
    #print( len(upa_graph_res) )
    
    n_xaxis = []
    for x in range(0, len(network_graph_res)):
        n_xaxis.append(x)
        
    n_yaxis = []
    for value in network_graph_res:
        n_yaxis.append(value)

    e_xaxis = []
    for x in range(0, len(er_graph_res)):
        e_xaxis.append(x)
    e_yaxis = []
    for value in er_graph_res:
        e_yaxis.append(value)
        
    u_xaxis = []
    for x in range(0, len(upa_graph_res)):
        u_xaxis.append(x)
    u_yaxis = []
    for value in upa_graph_res:
        u_yaxis.append(value)

    plt.plot(n_xaxis, n_yaxis, color='r')
    plt.plot(e_xaxis, e_yaxis, color='b')
    plt.plot(u_xaxis, u_yaxis, color='g')
    plt.xlabel('Nodes Removed')
    plt.ylabel('Largest Connected Components Sizes')
    plt.title('Comparison of Resilience For Targeted Graph Attack')
    red_patch = mpatches.Patch(color='red', label='Network Graph')
    blue_patch = mpatches.Patch(color='blue', label='ER Graph, p = .004')
    green_patch = mpatches.Patch(color='green', label ='UPA Graph, m = 2')
    plt.legend(handles=[red_patch,blue_patch,green_patch], loc=1)
    plt.show()

#############################################################
###
def random_order(graph):
    """
    return a list consisting of the nodes in a graph in random order.
    """
    result = []
    for value in graph.keys():
        result.append(value)
        
    random.shuffle(result)
    return result

def undirected_ER_graph_generator(num_nodes, probability):
    '''
    generate a undirected ER graph
    input: number of notdes and the probability to generate a edge
    output: dictionary representating a generated graph
    '''
    graph = {node:set() for node in range(num_nodes)}
    for node in graph:
        for target in range(num_nodes):
            if target != node:
                p = random.random()
                if p <= probability:
                    graph[node].add(target)
                    graph[target].add(node)
    return graph

def upa_graph(total_number_of_nodes, initial_number_of_nodes, num_edges):
    """ 
    generate an undirected preferencial attachment graph
    """
    ugraph = undirected_ER_graph_generator(initial_number_of_nodes, 1)
    random_connect = UPATrial(initial_number_of_nodes)
    for new_node in range(initial_number_of_nodes, total_number_of_nodes):
        new_edges = random_connect.run_trial(num_edges)
        ugraph[new_node] = new_edges
        for old_node in new_edges:
            ugraph[old_node].add(new_node)
    return ugraph

###################################################################
###
def test_resilient(resilience):
    '''
    test if the graph is resilient, that is:
    if the size of the largest cc is within 25% of its original value,
        after 20% nodes removed
    '''
    return resilience[int((len(resilience)-1)*0.2)]>((len(resilience)-1)-(len(resilience)-1)*0.25)


########################################################################
def wrapper(func, *args, **kwargs):
    def wrapped():
        return func(*args, **kwargs)
    return wrapped

###################################################################
###
def targete_order_speed_comparison():  
    s_xaxis = []
    s_yaxis = []
    f_xaxis = []
    f_yaxis = []

    for nodes in range(10, 1000, 10):
        new_graph1 = upa_graph(nodes, 5, 5)
        new_graph2 = copy_graph(new_graph1)
        
        # do the slow
        wrapped = wrapper(targeted_order, new_graph1)
        tot_time = timeit.timeit(wrapped, number=1)
        s_xaxis.append( nodes )
        s_yaxis.append( tot_time )       
                 
        # do the fast
        wrapped = wrapper(fast_targeted_order, new_graph2)
        tot_time = timeit.timeit(wrapped, number=1)
        f_xaxis.append( nodes )
        f_yaxis.append( tot_time )
    
    plt.plot(s_xaxis, s_yaxis, color='r')
    plt.plot(f_xaxis, f_yaxis, color='b')
    
    plt.xlabel('Number of Nodes UPA Graphs, m=5')
    plt.ylabel('Time')
    plt.title('Time Comparison Target Order Algorithms - Python 3.5.2 - Anaconda')
    red_patch = mpatches.Patch(color='red', label='targeted_order')
    blue_patch = mpatches.Patch(color='blue', label='fast_targeted_order')
    plt.legend(handles=[red_patch,blue_patch], loc=2)
    plt.show()
    
        

###################################################################
###

NETWORK_URL = "http://storage.googleapis.com/codeskulptor-alg/alg_rf7.txt"

### 1. The network graph # with 1239 nodes and 3047 edges
network_graph = load_graph(NETWORK_URL)

# print(len(network_graph))
# network_graph_nodes = network_graph.keys()
#network_graph_res = compute_resilience(network_graph, random_order(network_graph) )

## 2. The ER graph
er_graph = generate_ugraph(1239, .004)

#er_graph_nodes = er_graph.keys()
#er_graph_res = compute_resilience(er_graph, random_order(er_graph))

## 3. The DP graph
upagraph = upa_graph(1239, 2, 2)

#upagraph_res = compute_resilience(upagraph, random_order(upagraph))

#plot_graphs_hw_one(network_graph_res, er_graph_res, upagraph_res)

#print( fast_targeted_order(make_complete_ugraph(20)) )

#print( test_resilient(network_graph_res) )
#print( test_resilient(upagraph_res) )
#print( test_resilient(er_graph_res) )

## Question 2.
## Both the ER and UPA graph seem to be resilient after the removal of 20% of their nodes.
## The network graph seems to experience a bigger drop in reseliency which I think may be
## attributed to the nodes that were removed randomly.

## Question 3.
# targeted_order_speed_comparison()

# Question 4.

er_graph_res_targeted = compute_resilience(er_graph, fast_targeted_order(er_graph))
print("ER graph done")
upagraph_res_targeted = compute_resilience(upagraph, fast_targeted_order(upagraph))
print("UPA Graph done")
net_graph_res_targeted = compute_resilience(network_graph, fast_targeted_order(network_graph))
print("Network Graph done")
plot_graphs_hw_one(net_graph_res_targeted,er_graph_res_targeted,upagraph_res_targeted)
